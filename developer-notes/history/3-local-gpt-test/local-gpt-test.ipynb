{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/anderson/.local/lib/python3.12/site-packages (4.40.2)\n",
      "Requirement already satisfied: torch in /home/anderson/.local/lib/python3.12/site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/anderson/.local/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/anderson/.local/lib/python3.12/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/anderson/.local/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/anderson/.local/lib/python3.12/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/anderson/.local/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/anderson/.local/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/anderson/.local/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/anderson/.local/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anderson/.local/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/anderson/.local/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anderson/.local/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/anderson/.local/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save the GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model name\n",
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anderson/.local/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained GPT-2 model and tokenizer from Hugging Face\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and tokenizer locally\n",
    "model_save_path = \"./gpt2/\"\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "model.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model Locally and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and tokenizer from the local path\n",
    "local_tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n",
    "local_model = GPT2LMHeadModel.from_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=50):\n",
    "    inputs = local_tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Set the pad_token_id to the eos_token_id to suppress the warning\n",
    "    outputs = local_model.generate(\n",
    "        inputs, \n",
    "        max_length=max_length, \n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=local_tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    return local_tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of France?\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you meet me tomorrow? Yes I can meet you tomorrow. I am going to meet you tomorrow. I am going to meet you tomorrow. I am going to meet you tomorrow. I am going to meet you tomorrow. I am going to meet\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you meet me tomorrow ? Yes I can meet\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aslam o Alikm!\\n\\nThe Prophet (peace and blessings of Allaah be upon him) said, \"O you who believe! Do not believe in the Messenger of Allaah (peace and blessings of Allaah be upon him) and do not'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Aslam o Alikm !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would you play CoD?\\n\\nI would play CoD. I would play CoD. I would play CoD. I would play CoD. I would play CoD. I would play CoD. I would play CoD.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Would you play CoD ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def question_answer(prompt):\n",
    "    # Gen Response\n",
    "    response = generate_text(prompt)\n",
    "\n",
    "    # Remove the prompt from the response\n",
    "    cleaned_response = response.replace(prompt, \"\").strip()\n",
    "\n",
    "    # Replace multiple spaces and newlines with a single space\n",
    "    cleaned_response = re.sub(r'\\s+', ' ', cleaned_response)\n",
    "\n",
    "    # Remove repeating sequences\n",
    "    def remove_repeating_sequences(text):\n",
    "        words = text.split()\n",
    "        seen = {}\n",
    "        result = []\n",
    "        i = 0\n",
    "\n",
    "        while i < len(words):\n",
    "            seq = tuple(words[i:i+5])  # Look ahead for sequences of 5 words\n",
    "            if seq in seen:\n",
    "                break  # Stop processing if a sequence is repeated\n",
    "            seen[seq] = True\n",
    "            result.extend(seq)\n",
    "            i += len(seq)\n",
    "        \n",
    "        return ' '.join(result)\n",
    "\n",
    "    final_response = remove_repeating_sequences(cleaned_response)\n",
    "    \n",
    "    return final_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure. I'm not sure if I'd play it. I'm not sure if I'd play it. What's your favorite game of all time? I'm not sure\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer(\"Would you play CoD?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
